{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1628b94f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langgraph.graph.message import MessagesState\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "from langgraph.types import interrupt, Command\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "llm = init_chat_model(\"openai:gpt-4o-mini\")\n",
        "\n",
        "conn = sqlite3.connect(\n",
        "    \"memory.db\",\n",
        "    check_same_thread=False,\n",
        ")\n",
        "\n",
        "config = {\n",
        "    \"configurable\" : {\n",
        "        \"thread_id\": \"3\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a6196f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "class State(MessagesState):\n",
        "    custom_stuff : str\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0188b6e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_human_feedback(poem: str):\n",
        "    \"\"\"\n",
        "    Asks the user for feedback on the poem.\n",
        "    Use this before returning the final response.\n",
        "    \"\"\"\n",
        "    feedback = interrupt(f\"Here is the poem, tell me what you think\\n{poem}\")\n",
        "    return feedback\n",
        "\n",
        "tools = [get_human_feedback]\n",
        "tools_by_name = {tool.name : tool for tool in tools}\n",
        "llm_with_tools = llm.bind_tools(tools=tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    response = llm_with_tools.invoke(\n",
        "        f\"\"\"\n",
        "        You are an expert in maiking poems.\n",
        "        User the `get_human_feedback` tool to get feedback on your poem.\n",
        "        Only after you receive positive feedvack you can return the final poem.\n",
        "        ALWAYS ASK FOR FEEDBACK FIRST.\n",
        "        Here is  the conversation history:\n",
        "        {state[\"messages\"]}\n",
        "        \"\"\"\n",
        "    )\n",
        "    return {\"messages\":[response]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c90e12",
      "metadata": {},
      "outputs": [],
      "source": [
        "from multiprocessing import context\n",
        "from typing import Literal\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "def tool_node(state: dict):\n",
        "    result = []\n",
        "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
        "        tool = tools_by_name[tool_call[\"name\"]]\n",
        "        observation = tool.invoke(tool_call[\"args\"])\n",
        "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
        "\n",
        "    return {\"messages\":result}\n",
        "\n",
        "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    if last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    \n",
        "    return END\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97322cc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from subprocess import check_output\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_conditional_edges(\"chatbot\", should_continue, [\"tools\", END] )\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "graph = graph_builder.compile(\n",
        "    checkpointer=SqliteSaver(conn)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6d88b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = graph.invoke(\n",
        "    {\n",
        "        \"messages\" : [\n",
        "            {\"role\":\"user\", \"content\":\"Please make a poem about Python code.\"}\n",
        "        ]\n",
        "    },\n",
        "    config = config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "029120a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "for message in result[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8fa086f",
      "metadata": {},
      "outputs": [],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a71859",
      "metadata": {},
      "outputs": [],
      "source": [
        "response = Command(resume=\"It's too long!\")\n",
        "\n",
        "result = graph.invoke(response, config=config)\n",
        "\n",
        "for message in result[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "998c3df7",
      "metadata": {},
      "outputs": [],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9c21406",
      "metadata": {},
      "outputs": [],
      "source": [
        "response = Command(resume=\"It's good!\")\n",
        "\n",
        "result = graph.invoke(response, config=config)\n",
        "\n",
        "for message in result[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af07137",
      "metadata": {},
      "outputs": [],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e280d851",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
